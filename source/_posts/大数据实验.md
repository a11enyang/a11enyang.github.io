---
title: 大数据实验 hadoop安装和配置
date: 2020-05-05 18:12:02
tags:
	- 大数据实验
	- hadoop
	- BUPT
---

![image-20200505211201857](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200505211201857.png)

<!-- more -->

### 一、实验目的

正确在本地电脑上安装和运行伪分布式hadoop系统，产生对hadoop的初步认识和理解。



### 二、实验内容

1. 在本地电脑上正确安装和运行伪分布式hadoop系统
2. 安装完成后，寻找英文网页数据，在本机上运行hadoop自带的WordCount可执行文件，并产生输出结果



### 三、试验环境

macOS Catalinna10.15.3 + hadoop 3.2.1



### 四、实验过程

- 修改主机名

  ```bash
  sudo scutil --set HostName localhost
  ```

- ssh免密登录

  ```bash
  （1）ssh-keygen -t rsa      （一路回车直到完成）
  （2）cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  （3）chmod og-wx ~/.ssh/authorized_keys
  ```

- 安装hadoop

  ```bash
  brew install hadoop
  ```

- 修改相关文件

  ```
  修改core-site.xml
  修改hdfs-site.xml
  修改环境变量
  修改hadoop-env.sh
  ```

- 格式化HDFS

  ```bash
  ./hdfs namenode -format
  ```

- 启动hadoop

  ```bash
  ./start-dfs.sh
  ```

- 查看hadoop是否启动成功

  ```bash
  austin@localhost bin$jps
  37568 Jps
  37408 ResourceManager
  36983 NameNode
  37082 DataNode
  37214 SecondaryNameNode
  37503 NodeManager
  ```

  ![image-20200409095109976](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409095109976.png)

- 访问NameNode结点网站 http://localhost:9870/

  ![image-20200409093948517](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409093948517.png)

- 修改文件

  ```bash
  修改mapred-site.xml
  修改yarn-site.xml
  ```

- 启动yarn

  ```bash
  sbin/start-yarn.sh
  ```

- 访问网站http://localhost:8088/

  ![](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409100440345.png)



### 五、实验结果

- 运行hadoop自带的wordcount程序

- 启动hadoop系统

  ![image-20200409095109976](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409095109976.png)

- 在HDFS系统中创建一个input目录

  ```bash
  hadoop fs -mkdir /input
  ```

  ![image-20200409101020933](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409101020933.png)

- 查询HDFS的目录

  ```bash
  hadoop fs -ls
  ```

  ![image-20200409101405784](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409101405784.png)

- 上传传一个两个txt文件到HDFS中

  ```bash
  hadoop fs -put README.txt /input
  hadoop fs -put NOTICE.txt /input
  ```

  ![image-20200409104650797](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409104650797.png)

- 运行java包

  ```bash
  hadoop jar /usr/local/Cellar/hadoop/3.2.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount /input /output2
  ```

  ![image-20200409104726268](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409104726268.png)

- 查看内容

  ```bash
  hadoop fs -cat /output2/part-r-00000
  ```

  ![image-20200409104844738](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409104844738.png)

  

- 查看系统运行状态

  ![image-20200409110553497](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409110553497.png)

  ![image-20200409111612269](https://cdn.jsdelivr.net/gh/a11enyang/Picture/img2/image-20200409111612269.png)

### 五、附录

#### 实验结果总结

- 系统运行情况

  正常运行，可以正常访问HDFS

- 实验数据说明

  | 文件名称   | 文件大小 |
  | ---------- | -------- |
  | NOTICE.txt | 21.61 KB |
  | README.txt | 1.33 KB  |

  NOTICE.txt内容(由于内容太多，只选取了一部分)

  ```txt
  This product includes software developed by The Apache Software
  Foundation (http://www.apache.org/).
  
  The binary distribution of this product bundles binaries of
  org.iq80.leveldb:leveldb-api (https://github.com/dain/leveldb), which has the
  following notices:
  * Copyright 2011 Dain Sundstrom <dain@iq80.com>
  * Copyright 2011 FuseSource Corp. http://fusesource.com
  
  The binary distribution of this product bundles binaries of
  AWS SDK for Java - Bundle 1.11.375,
  AWS Java SDK for AWS KMS 1.11.375,
  AWS Java SDK for Amazon S3 1.11.375,
  AWS Java SDK for AWS STS 1.11.375,
  JMES Path Query library 1.0,
  which has the following notices:
   * This software includes third party software subject to the following
   copyrights: - XML parsing and utility functions from JetS3t - Copyright
   2006-2009 James Murty. - JSON parsing and utility functions from JSON.org -
   Copyright 2002 JSON.org. - PKCS#1 PEM encoded private key parsing and utility
   functions from oauth.googlecode.com - Copyright 1998-2010 AOL Inc.
  
  The binary distribution of this product bundles binaries of
  Gson 2.2.4,
  which has the following notices:
  
                              The Netty Project
                              =================
  
  Please visit the Netty web site for more information:
  
    * http://netty.io/
  
  Copyright 2014 The Netty Project
  
  The Netty Project licenses this file to you under the Apache License,
  version 2.0 (the "License"); you may not use this file except in compliance
  with the License. You may obtain a copy of the License at:
  .....
  ```

  

  README.txt

  ```txt
  For the latest information about Hadoop, please visit our website at:
  
     http://hadoop.apache.org/
  
  and our wiki, at:
  
     http://wiki.apache.org/hadoop/
  
  This distribution includes cryptographic software.  The country in 
  which you currently reside may have restrictions on the import, 
  possession, use, and/or re-export to another country, of 
  encryption software.  BEFORE using any encryption software, please 
  check your country's laws, regulations and policies concerning the
  import, possession, or use, and re-export of encryption software, to 
  see if this is permitted.  See <http://www.wassenaar.org/> for more
  information.
  
  The U.S. Government Department of Commerce, Bureau of Industry and
  Security (BIS), has classified this software as Export Commodity 
  Control Number (ECCN) 5D002.C.1, which includes information security
  software using or performing cryptographic functions with asymmetric
  algorithms.  The form and manner of this Apache Software Foundation
  distribution makes it eligible for export under the License Exception
  ENC Technology Software Unrestricted (TSU) exception (see the BIS 
  Export Administration Regulations, Section 740.13) for both object 
  code and source code.
  
  The following provides more details on the included cryptographic
  software:
    Hadoop Core uses the SSL libraries from the Jetty project written 
  by mortbay.org.
  ```

- ❌Debug过程

  >### hadoop3.2.1下MapReduce操作出现错误: 找不到或无法加载主类

  解决办法

  ```
  hadoop classpath
  在yarn-site中添加如下内容
  <configuration>
      <property>
          <name>yarn.application.classpath</name>
          <value>输入刚才返回的Hadoop classpath路径</value>
      </property>
  </configuration>
  ```

- **实验体会**

  ```
  1.安装与系统合适版本的hadoop
  2.善于利用日志文件进行debug
  3.通过学习前人的安装经验来减少障碍，少走弯路
  4.对hadoop系统有初步认识。文件分块存储，不同块可分布在不同机器节点上，通过元数据记录文件块位置；应用顺序读取各个块；
  ```

- 参考内容

  https://blog.csdn.net/qq_41684957/article/details/81710190

  https://blog.csdn.net/hongxiao2016/article/details/88919176

  https://blog.csdn.net/CHL123456789/article/details/88662085

  https://blog.csdn.net/vbirdbest/article/details/88189753

  
